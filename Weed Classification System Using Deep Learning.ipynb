{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP20li6uB5ka43ylJXgg3kW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"cc_f0yOAKSQh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751269284249,"user_tz":-300,"elapsed":54653,"user":{"displayName":"Muhammad Bilal","userId":"01228506414372820288"}},"outputId":"d618b97e-2aa9-43e8-81ce-20aa8e7a4407"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import tensorflow as tf\n","import pandas as pd\n","import os\n","from sklearn.model_selection import train_test_split\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","\n","DATA_DIR = \"/content/drive/MyDrive/WeedDetectionDataset/\"\n","CSV_PATH = \"/content/drive/MyDrive/labels.csv\"\n","\n","df = pd.read_csv(CSV_PATH)\n","\n","image_paths = []\n","labels = []\n","\n","for _, row in df.iterrows():\n","    img_path = os.path.join(DATA_DIR, row['Filename'])\n","    if os.path.exists(img_path):\n","        image_paths.append(img_path)\n","        labels.append(row['Label'])\n","    else:\n","        print(f\"Missing image: {img_path}\")\n","\n","train_paths, test_paths, y_train, y_test = train_test_split(\n","    image_paths, labels, test_size=0.2, stratify=labels, random_state=42\n",")\n","\n","label_to_species = dict(zip(df['Label'], df['Species'])) if 'Species' in df.columns else None\n","\n","\n"]},{"cell_type":"code","source":["species_list = df.drop_duplicates('Label').sort_values('Label')['Species'].tolist()"],"metadata":{"id":"gzxwoN6PFz_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DeepWeedsDatasetTF(tf.data.Dataset):\n","    def __new__(cls, image_paths, labels, img_size=(224, 224), batch_size=32, shuffle=True):\n","        num_classes = len(set(labels))\n","\n","        def _load_and_preprocess(path, label):\n","            image = tf.io.read_file(path)\n","            image = tf.image.decode_jpeg(image, channels=3)\n","            image = tf.image.resize(image, img_size)\n","            image = tf.cast(image, tf.float32) / 255.0\n","            label = tf.one_hot(label, num_classes)\n","            return image, label\n","\n","        ds = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n","        if shuffle:\n","            ds = ds.shuffle(buffer_size=1000)\n","        ds = ds.map(_load_and_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n","        ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n","        return ds"],"metadata":{"id":"LP3wsnIwTVqs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_ds = DeepWeedsDatasetTF(train_paths, y_train)\n","test_ds = DeepWeedsDatasetTF(test_paths, y_test, shuffle=False)\n"],"metadata":{"id":"iGfl8_VnRqSp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Train batches:\", len(train_ds))\n","print(\"Test batches:\", len(test_ds))"],"metadata":{"id":"ZvZ3jg_tTZY-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751269309847,"user_tz":-300,"elapsed":48,"user":{"displayName":"Muhammad Bilal","userId":"01228506414372820288"}},"outputId":"a03d99c1-902f-4751-b554-facebcd27f1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train batches: 197\n","Test batches: 50\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras import layers, models, optimizers\n","\n","IMG_SIZE = (224, 224, 3)\n","\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=IMG_SIZE)\n","\n","base_model.trainable = False\n","\n","model = models.Sequential([\n","    base_model,\n","    layers.GlobalAveragePooling2D(),\n","    layers.Dense(9, activation='softmax')\n","])\n","\n","model.compile(\n","    optimizer=optimizers.Adam(learning_rate=1e-4),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n"],"metadata":{"id":"U2bsCy54VzTG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751269386003,"user_tz":-300,"elapsed":3350,"user":{"displayName":"Muhammad Bilal","userId":"01228506414372820288"}},"outputId":"8fbda19c-91ec-4191-a2d7-87bc74e16d7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"]}]},{"cell_type":"code","source":["\n","num_epochs = 20\n","\n","loss_fn = tf.keras.losses.CategoricalCrossentropy()\n","optimizer = tf.keras.optimizers.Adam()\n","\n","model.optimizer = optimizer\n","\n","train_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n","val_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n","\n","train_acc_list = []\n","val_acc_list = []\n","epochs_list = []\n","\n","@tf.function\n","def train_step(images, labels):\n","    with tf.GradientTape() as tape:\n","        predictions = model(images, training=True)\n","        loss = loss_fn(labels, predictions)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","    train_acc_metric.update_state(labels, predictions)\n","    return loss\n","\n","@tf.function\n","def val_step(images, labels):\n","    predictions = model(images, training=False)\n","    val_acc_metric.update_state(labels, predictions)\n","\n","    for epoch in range(num_epochs):\n","\n","        train_acc_metric.reset_state()\n","        val_acc_metric.reset_state()\n","\n","\n","        for images, labels in train_ds:\n","            train_step(images, labels)\n","\n","        train_accuracy = train_acc_metric.result() * 100\n","\n","\n","        for images, labels in test_ds:\n","            val_step(images, labels)\n","\n","        val_accuracy = val_acc_metric.result() * 100\n","\n","\n","        train_acc_list.append(train_accuracy.numpy())\n","        val_acc_list.append(val_accuracy.numpy())\n","        epochs_list.append(epoch + 1)\n","\n","        print(f\"Epoch [{epoch + 1}/{num_epochs}]\")\n","        print(f\"Train Accuracy: {train_accuracy:.2f}% | Val Accuracy: {val_accuracy:.2f}%\")\n","\n"],"metadata":{"id":"V64Kh9Ql5KpZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","correct = 0\n","total = 0\n","\n","for images, labels in test_ds:\n","    predictions = model(images, training=False)\n","    pred_labels = tf.argmax(predictions, axis=1)\n","    true_labels = tf.argmax(labels, axis=1)\n","\n","    correct += tf.reduce_sum(tf.cast(pred_labels == true_labels, tf.float32)).numpy()\n","    total += labels.shape[0]\n","\n","print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"],"metadata":{"id":"FU__k0rKdI2X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","import numpy as np\n","\n","all_preds = []\n","all_labels = []\n","\n","for images, labels in test_ds:\n","    predictions = model(images, training=False)\n","\n","\n","    pred_labels = tf.argmax(predictions, axis=1)\n","\n","\n","    true_labels = tf.argmax(labels, axis=1)\n","\n","    all_preds.extend(pred_labels.numpy())\n","    all_labels.extend(true_labels.numpy())\n","\n","all_preds = np.array(all_preds)\n","all_labels = np.array(all_labels)\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(all_labels, all_preds, target_names=list(label_to_species.values())))\n"],"metadata":{"id":"04znEhLWes0_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_path = \"/content/resnet50.keras\"\n","\n","resnet_model.save(model_path)\n","\n","print(f\"Model saved at {model_path}\")"],"metadata":{"id":"CR4PLEgZe_JZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shutil\n","CSV_PATH = \"/content/drive/MyDrive/labels.csv\"\n","IMG_DIR = \"/content/drive/MyDrive/WeedDetectionDataset/\"\n","OUTPUT_DIR = \"/content/deepweed-yolo/\"\n","\n","\n","for split in ['train', 'val']:\n","    os.makedirs(f\"{OUTPUT_DIR}/images/{split}\", exist_ok=True)\n","    os.makedirs(f\"{OUTPUT_DIR}/labels/{split}\", exist_ok=True)\n","\n","\n","df = pd.read_csv(CSV_PATH)\n","\n","\n","train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['Label'], random_state=42)\n","\n","\n","def process_split(split_df, split_name):\n","    for _, row in split_df.iterrows():\n","        filename = row['Filename']\n","        label = int(row['Label'])\n","\n","\n","        src_img_path = os.path.join(IMG_DIR, filename)\n","        dst_img_path = os.path.join(OUTPUT_DIR, f\"images/{split_name}/{filename}\")\n","        dst_label_path = os.path.join(OUTPUT_DIR, f\"labels/{split_name}/{filename.replace('.jpg', '.txt')}\")\n","\n","\n","        if os.path.exists(src_img_path):\n","            shutil.copy(src_img_path, dst_img_path)\n","\n","\n","            with open(dst_label_path, 'w') as f:\n","                f.write(f\"{label} 0.5 0.5 1.0 1.0\\n\")\n","        else:\n","            print(f\"Missing image: {src_img_path}\")\n","\n","\n","process_split(train_df, \"train\")\n","process_split(val_df, \"val\")\n","\n","\n","class_names = df.drop_duplicates(\"Label\").sort_values(\"Label\")[\"Species\"].tolist()\n","\n","yaml_path = os.path.join(OUTPUT_DIR, \"data.yaml\")\n","with open(yaml_path, \"w\") as f:\n","    f.write(f\"path: {OUTPUT_DIR}\\n\")\n","    f.write(f\"train: images/train\\n\")\n","    f.write(f\"val: images/val\\n\")\n","    f.write(f\"nc: {len(class_names)}\\n\")\n","    f.write(f\"names: {class_names}\\n\")\n","\n","print(\" YOLO dataset ready!\")\n","print(\" Output directory:\", OUTPUT_DIR)\n","print(\" data.yaml created at:\", yaml_path)"],"metadata":{"id":"GctJ1cOWvmvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"id":"oh11GiH2wSGE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Loading a YOLOv11 model\n","model = YOLO(\"yolo11n.pt\")\n","\n","# Training on deepweed\n","model.train(data='/content/deepweed-yolo/data.yaml', epochs=10,imgsz=640)\n","\n","# Predict\n","results = model.predict(source='/content/deepweed-yolo/images/val', save=True)"],"metadata":{"id":"_qC-MnsV6GF0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import os\n","from PIL import Image\n","import random\n","\n","pred_dir = \"/content/runs/detect/train\"\n","all_images = [f for f in os.listdir(pred_dir) if f.endswith(\"_pred.jpg\")]\n","random_imgs = random.sample(all_images, min(5, len(all_images)))\n","\n","plt.figure(figsize=(15, 10))\n","for i, img_name in enumerate(random_imgs):\n","    img_path = os.path.join(pred_dir, img_name)\n","    img = Image.open(img_path)\n","\n","    plt.subplot(1, len(random_imgs), i + 1)\n","    plt.imshow(img)\n","    plt.axis(\"off\")\n","    plt.title(img_name)\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"EiSgAK3JwUwG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","model = YOLO('/content/runs/detect/train/weights/best.pt')\n","\n","metrics = model.val(data='/content/deepweed-yolo/data.yaml')\n","\n","print(metrics)"],"metadata":{"id":"2-X3hs3d7SdD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from PIL import Image\n","\n","img = Image.open('content/runs/detect/train/results.png')\n","plt.figure(figsize=(15, 10))\n","plt.imshow(img)\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"MalE8bWB7oux"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from tensorflow.keras.applications.resnet50 import preprocess_input\n","from tensorflow.keras.preprocessing import image as keras_image\n","\n","\n","yolo_weights_path = \"/content/runs/detect/train/weights/best.pt\"\n","resnet_model_path = \"/content/resnet50.keras\"\n","img_path = \"/content/drive/MyDrive/WeedDetectionDataset/20160928-141437-0.jpg\"\n","class_names = species_list\n","\n","\n","yolo_model = YOLO(yolo_weights_path)\n","\n","\n","results = yolo_model(img_path)\n","image = Image.open(img_path).convert(\"RGB\")\n","\n","\n","resnet_model = tf.keras.models.load_model(resnet_model_path)\n","\n","\n","for i, box in enumerate(results[0].boxes.xyxy.cpu().numpy()):\n","    x1, y1, x2, y2 = map(int, box[:4])\n","\n","\n","    cropped_img = image.crop((x1, y1, x2, y2)).resize((224, 224))\n","\n","\n","    img_array = keras_image.img_to_array(cropped_img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array = preprocess_input(img_array)\n","\n","\n","    preds = resnet_model.predict(img_array, verbose=0)\n","    pred_class = class_names[np.argmax(preds[0])]\n","\n","    print(f\"Box {i+1}: ({x1}, {y1}, {x2}, {y2}) → {pred_class}\")\n"],"metadata":{"id":"nk4bSdAV-iio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image, ImageDraw, ImageFont\n","image_draw = image.copy()\n","draw = ImageDraw.Draw(image_draw)\n","\n","try:\n","    font = ImageFont.truetype(\"arial.ttf\", size=16)\n","except:\n","    font = ImageFont.load_default()\n","\n","for i, box in enumerate(results[0].boxes.xyxy.cpu().numpy()):\n","    x1, y1, x2, y2 = map(int, box[:4])\n","\n","\n","    cropped_img = image.crop((x1, y1, x2, y2)).resize((224, 224))\n","    img_array = keras_image.img_to_array(cropped_img)\n","    img_array = np.expand_dims(img_array, axis=0)\n","    img_array = preprocess_input(img_array)\n","\n","\n","    preds = resnet_model.predict(img_array, verbose=0)\n","    pred_label = np.argmax(preds[0])\n","    pred_name = class_names[pred_label]\n","    confidence = np.max(preds[0])\n","\n","    label_text = f\"{pred_label}: {pred_name} ({confidence:.2f})\"\n","\n","\n","    draw.rectangle([x1, y1, x2, y2], outline=\"red\", width=2)\n","    text_position = (x1 + 5, max(0, y1 - 20))\n","    draw.text(text_position, label_text, fill=\"red\", font=font)\n","\n","plt.figure(figsize=(10, 8))\n","plt.imshow(image_draw)\n","plt.axis(\"off\")\n","plt.title(\"YOLO Detections + ResNet50 Class Predictions\")\n","plt.show()"],"metadata":{"id":"o6pE3YdRCLF2"},"execution_count":null,"outputs":[]}]}